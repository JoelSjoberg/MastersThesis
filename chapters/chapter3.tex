Before a deep learning model is created it is necessary to have extensive knowledge about the data in the project. As certain tumors may be heterogeneous\cite{friedmann2014glioblastoma}, their biological information may make them hard to group which would make model generalization difficult. The analysis explained here is to determine whether Raman spectrum can sufficiently sort the different samples into the sample classes (LGm1 - 6). In this chapter the data available to the project is examined in greater detail; details for how the Raman spectrum were prepared is given to document the preprocessing of spectrum for future use. The chapter begins by describing the mathematical representation of the samples. The number of samples is deemed too small for use in a deep learning model, arguments are given for how each sample may be separated into individual spectras after which a argument is made in favor of this representation. This separation yields a drastic increase in the number of training examples available which reignites the possibility of deep learning models in this context. The chapter then proceeds to explain how the data is to be balanced. An unbalanced dataset would likely invoke bias into the deep learning model which would introduce uncertainty in it's desired predictive capabilities. This is done by duplicating samples in sample-classes which are underrepresented in the dataset. Furthermore, this balancing is performed to maintain majority and minority classes which retains some distributional information from the original dataset. Certain problematic samples are also discarded in this section to alleviate memory issues which would otherwise be present on a modern computer. Feature selection is also performed to extract the features best descriptive of the different classes with respect to the other classes. This step further aids in alleviating memory issues and run time, the necessity is further motivated by comparison of the results from the extraction. The chapter ends with an analysis of each sample using hierarchical clustering with complete linkage in an attempt to detect and remove eventual outliers within the samples themselves.


\section{Data Representation}
The data consists of the Raman-spectrum extracted from the tissue of glioma tumors from 45 patients. Multiple samples of tissue was extracted from the same patient in some cases, yielding several samples for the respective patient. To maintain separation among the patients the samples are sorted by the patient to whom they belong. This is necessary at the exploration stage since the data at one point will be divided into training and testing examples. The testing data will consist of unique patients to avoid scenarios in which the model is familiar with a patients tumor sample. This structure also allow for ease in handling the amount of patients in sample-class. There is also large variation with regard to the sample shape within the data. Each sample is a 3-dimensional array of shape $(w, h, 1738)$ where $w$ and $h$ are the width and height of the sample respectively. This formalization is necessary, as width and height have non-zero variance among different samples. The shape is a result of how the tissue was scanned. In each case the tissue was placed inside the instrument and scanned successively from side to side. This makes it possible to display each sample as an image, where the third dimension (1738) could serve as a color value. The number $1738$ is constant through all samples and represent the length of the Raman-spectra, each element a unique frequency. Each element inside these arrays is a real number without clear bounds. The largest absolute element found within is $79427.0625$, some values are negative which is confirmed by the providers to have significance for the projects purpose. The project aims to predict the which subdivision the spectra belong to by feeding in one of these samples i.e. one vector of shape $(1, 1738)$. Displaying each sample is possible by visualizing each spectra as a line, each patient has $w * h$ spectras. Before the lines are drawn the maximum absolute value of each frequency within the entire dataset. Using these the frequencies of each spectra may be normalized to have a maximum value of 1. By normalization the plots may be compared to identify outliers and determine necessary preprocessing measures. An example of this visualization is displayed in the appendix \ref{appendix:spectraplot}. There is shown a comparison by the common pattern these samples portray compared to one of the samples which will be removed from the dataset. This comparison is only one method of detecting outliers, the reason for this samples removal, along with the removal of other problematic samples is further motivated below.

\section{Data preparation}
The preparation of the data is vital to form non-biased models, provided that the data can be restructured and re-scaled to sufficiently represent the majority of the samples. Should this be impossible the resulting predictive model will fail to grasp the necessary features in the data for forming predictions. The model would in this respect overfit to the data used to train it. To avoid this we preform a qualitative analysis on the data to determine the predictability. Each sample is categorized according to their sub division, there are six distinct subdivisions defined by Ceccarelli et al.\cite{cellsubsets}, the labels are denoted by LGm1 - 6.

\subsection{Balancing}
The data used to train a model must in some way be balanced. Should one label-class be over-represented with respect to the others, the model will as a consequence of it's learning-algorithm become biased towards certain predictions \textbf{PROVE THIS!}. The data suffers heavily from this problem, a table of the number of spectra in each class may be seen in Table \ref{table:1}.
\\

\begin{table}[h!]
\centering
 \begin{tabular}{||c c c c c c c||} 
 \hline
 Class & LGm1 & LGm2 & LGm3 & LGm4 & LGm5 & LGm6 \\ [0.5ex] 
 \hline\hline
 \# of samples & 5& 16 & 7 & 13 & 15 & 5 \\ 
 \hline
 \# of spectra & 37319 & 210586 & 39636 & 50660 & 62256 & 20176 \\
 \hline
 percentage & 9\%& 50\% & 9\% & 12\% & 15\% & 5\% \\
 \hline

\end{tabular}
\caption{Table showing the distribution of data in the initial dataset}
\label{table:1}
\end{table}

\newpage
Table \ref{table:1} shows the per class separation in the data, the first row shows the labels of each class. The second row shows the number of samples belonging to each class, these are the tumors which will be analysed. The third row display the total number of spectra across each class, these must be considered when balancing is performed. The last row of table \ref{table:1} shows the percentage each class makes of the entire dataset. Initially LGm2 is the majority class while LGm 6 is the minority, consisting of only $5$\% of the entire dataset. Some samples prove to be problematic as their size make them too big to load into memory. Some even included what appears to be erroneous readings. For simplicity they are removed from the analysis. Their plots are shown in appendix \textbf{FILL IN APPENDIX!}\ref{appendix:spectrumTable1}. The data is now represented in Table \ref{table:2}
\\

\begin{table}[h!]
\centering
 \begin{tabular}{||c c c c c c c||} 
 \hline
 Class & LGm1 & LGm2 & LGm3 & LGm4 & LGm5 & LGm6 \\ [0.5ex] 
 \hline\hline
 \# of samples & 5& 11 & 4 & 13 & 15 & 5 \\ 
 \hline
 \# of spectra & 37319 & 71846 & 14896 & 50660 & 62256 & 20176 \\
 \hline
 percentage & 15\%& 28\% & 6\% & 20\% & 24\% & 8\% \\
 \hline

\end{tabular}
\caption{The data distribution after removing problematic samples}
\label{table:2}
\end{table}


Before the data is balanced, the testing data is selected and separated from the rest. This is done by separating at least one patient and all their samples from the rest of the data. This way it will be possible to test if the model is overfit to the patients in training and if the patient samples are heterogeneous  with respect to the other samples of the same class. With the test-patients separated, balancing the classes which contain less elements by a factor larger than or equal to two than the majority class (LGm2) is done by repeating the spectrum in each sample by that factor. Following this method the majority class will stay the majority which is be crucial provided the sample pattern is correct. The resulting dataset is gained by doubling the samples in LGm1, quadrupling the samples in Lgm3 and tripling the samples in LGm6. The distributions of the final training dataset is shown in Table \ref{table:3}.


\begin{table}[h!]
\centering
 \begin{tabular}{||c c c c c c c||} 
 \hline
 Class & LGm1 & LGm2 & LGm3 & LGm4 & LGm5 & LGm6 \\ [0.5ex] 
 \hline\hline
\# of spectra & 22374	& 51698	& 11296	& 34276	& 43892	& 12976 \\
 \hline 
 Factor  & 2 & 1 & 4 & 1 & 1 & 3 \\
 \hline 
 \# of spectra & 44748 & 51698 & 45184 & 34276 & 43892 & 38928 \\
 \hline
 percentage & 17\%& 20\% & 17\% & 13\% & 17\% & 15\% \\
 \hline

\end{tabular}
\caption{Distribution of the training data}
\label{table:3}
\end{table}

Table \ref{table:3} shows the number of spectra before multiplying on row two and the number of spectra after on row four. The precentages on row five shows the distribution on the modified dataset. The percentages are now closer in scope,  meaning each class is now in relative balance to the other classes.

\subsection{Clustering}

To ensure each sample include relevant information requires intuitive analysis. During extraction it is possible droplets of certain fluids were present, it is also possible the laser hit the tissue at a thin point which would scan the plastic underneath. This data must be removed to avoid model dependency on erroneous spectra. To find and remove the erroneous spectra, a clustering method is used. A suggested method is the k-means clustering algorithm by MacQueen \cite{macqueen} performed on every spectra on a sample by sample analysis. The resulting clustering may be displayed as a 2-dimensional image, some of which are shown in \textbf{APPENDIX!!}. K-means do however suffer heavily from outlier influences, as these outliers may be present at this stage, it is necessary to consider other methods. Hierarchical clustering is a clustering method which avoids outlier dependency by separating each individual spectra into its own cluster and then reducing the number of clusters depending on the linkage type. Complete linkage is used to ensure diversity among the clusters, measured by euclidean distance\cite{scikit}. Each spectra is now labeled by a class number, all labels may be displayed as a two dimensional image due to the shape of the samples. Examples of such images are shown in appendix \ref{appendix:hierimg0}. The cluster shapes suggest certain outliers within all patients, these outliers are removed accordingly to retain the tissue information exclusively. \textbf{Note: I am still unsure of this step, the clusters seem to also capture what could be perfectly normal tissue. Raise this concern with supervisors, it is crutial to get this part right so as to present rigorous results. I have saved images using alternative distance metrics however they seem to largely suffer from the same problem (some even seem to recreate the tumor image entirely)}

\subsection{Feature selection}

\textbf{Note: Discuss the following with supervisors: feature selection is now done before clustering. The reason I describe clustering first is that I think it would be best to perform clustering first and then extract the features. This extraction did yield features which made the clustering results "make sense" so to speak. However the outliers (eventual plastic or other non-tumor substance) is present during this extraction, meaning non-tissue is taken into consideration during the process. Would it not be better to extract them after removing non-tumor samples? Then, the yielded features might be different! If this is not the case we can proceed without concern, but what if this fails?}
\\

Each number in the spectra is a frequency at which the scattered light is gathered. This light is expected to be sufficient for predicting the methylation-type of the tumor-tissue. Due to the number of spectra inside each sample memory quickly becomes an issue, it is therefore relevant to examine which frequencies would have the most impact on classification. For this reason the best features are extracted with SelectKBestfeatures \cite{scikit}. The 70 best features were extracted from each spectra which is shown to be appropriate to recreate the original tumorshape by performing clustering 