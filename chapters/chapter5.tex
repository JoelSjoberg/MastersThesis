
In this chapter we present conclusions regarding the analysis of spectra for detecting outliers, the performance of the machine learning model presented in Chapter 4 and provide suggestions for further analysis of the tumors and feature selection.

The features extracted form the data utilizes the ANOVA \textit{F-value} to score the features in the data. These features are extracted from the training set on principle, as we want to avoid any bias towards the validation and test sets. The features presented in this thesis are the features extracted before and after the samples have been separated from the outliers. The have found that the extracted features vary greatly depending on which samples are present in the training set, which brings the consistency of the results into question. This is perhaps not surprising given the reliance of variance in ANOVA. Switching even one sample in the training set has the potential shift the mean of the entire set. Combined with the fact that all spectra have more than $1700$ frequencies used in the calculations the squared distances to change yielding a different \textit{F-value} for each frequency. The use of f-classif is due to its capability of handling the negative values present within the data. There are other methods better suited for feature selection in context of classification i.e. chi-squared which does not handle negative values. For future tests, we suggest examining a method for transforming the data, such that all frequencies have a positive scope, which would allow feature extraction using chi-squared as scoring function for SelectKBest.

The modeling results suggest heterogeneity keep the model from generalizing to unseen data. Through multiple tests, where the architecture of the model has been modified in various ways, we conclude that the architecture appears arbitrary for training processes that last for approximately five hours. Provided the used pre-processing methods mentioned in Chapter 4 are used, the model always manages to learn the training set with accuracy ranging from $90\%$ and above. The models performance on the validation set is always insufficient due to the model over-representing certain categories. We also replace all samples in the validation set with samples drawn from the training set to test if any samples within the original validation set remain problematic after the outlier removal procedure. However, the results remain the same after training; this suggests the problem lies in heterogeneity among spectra from different samples rather than problematic samples in the validation set. The improvements to the models performance appear to stagnate after $100$ epochs, but it is still not certain the model can't improve further with a smaller learning rate trained on exponentially more epochs. Certain models have trained for days and even weeks, we have not had this possibility and consider it a worthy effort, as the longer training time may result in surprising results. Liu et al. also introduce a custom loss function which takes the distribution of the different categories into account \cite{liu2017deep}. We have attempted to replicate this loss by introducing weights proportional to the different categories which tune the gradient during training. This does not improve performance and the model remains at a similar level of performance. There might be an improvement by implementing the custom loss function and we suggest it should be considered in the future.

We also believe the classes which the model appears to prefer should be examined further; if the problem is independent of the model, the issue is then to be found either in the pre-processing methods or in the analysis stage explained in Chapter 3. We perform baseline correction on the spectra available, but the spectra in the dataset are actually selected frequencies from the complete spectra. It is possible the baseline correction algorithm is unable to remove the baseline sufficiently when all spectral signals are unavailable. Baseline correction might therefore not be suitable for this data and should be reconsidered during the analysis stage. Alternatively, different methods for baseline correction may be tested on the data, one possible alternative method would be to approximate the baseline using linear regression. Standardization retains huge values in certain frequencies, it is possible frequencies which possess large values are outliers (provided the frequencies are drawn from a normal distribution) and should therefore be removed. Maximum absolute value normalization is something we are certain is required for the model to comprehend the data due to the drastic change in scope for the values within the spectra.

The analysis in Chapter 3 shows that ward linkage is sufficient in detecting outliers compared to the frequency criterion. However, the outliers detected for certain samples appear after several othe rareas have been separated into other clusters. One interpretation of this is that the initial clusters differ more from the majority compared to the outliers and are therefore outliers themselves. We use this interpretation in this thesis but there is another interpretation based on the definition of ward linkage. Ward linkage depends on the definition of variance which depends on the mean of the sample under analysis. It is possible that certain clusters of tumor spectra may form prematurely due to having an inter cluster mean which differs considerably from the rest. In cases where few outliers are present in the sample, this may cause outliers to appear after the appearance of other clusters. This is shown in sample HF-2485 where clusters avoid the known outliers and instead sorts the outliers into a unique cluster once four clusters are allowed. This case requires a different solution regarding which cluster should be removed from the sample. The suggestion we give as an alternative solution is to use the distance between the means of the different clusters. The mean of the outlier cluster should be sufficiently distant from other clusters to be used as discriminator. This would need further testing for confirmation. Moreover, clustering methods are only usable in cases where outliers are known to be present; using clustering on a sample devoid of outliers will still produce clusters around parts of the sample, which is shown in the figures of Chapter 3. Allowing more clusters than necessary for outlier detection causes clusters to form around other tumor spectra which are usable in the training set. We also attempt to use baseline correction on the spectra before the clustering analysis, but this does not yield similar results, outliers become harder to spot and clusters appear to miss major areas where outliers are possible. The same occurs when using the features extracted by f-classif. In earlier tests, we have tried to separate the spectra by the frequency criterion, labeling all spectra as either outlier or non-outlier. Using f-classif, we extracted the features which best separate the data into outliers and non-outliers and attempted clustering following feature extraction. The results were now mixed and separated outliers extremely poorly compared to the straight forward application on spectra. Thus, we conclude that raw spectra is optimal for outlier detection using hierarchical clustering with ward linkage measuring with the \textit{Euclidean distance} metric.

These suggestions may yield better results for the model. Our tests suggest heterogeneity is the key problem in this analysis. However, it is not certain that this is the correct conclusion. It is still unclear how the heterogeneity among tumor samples is preserved in the Raman spectra we have available. One possible issue for this project is that the number of tumor samples available from unique patients is less than $50$. It is possible the model requires more unique patient samples to adequately learn the characteristics of the methylation categories. Deep learning models are extremely reliant on large sets of data, and it appears the data is the source of our conflicting results, rather than methodology. This problem is unfortunately hard to mitigate, as extracting and scanning new samples require a tremendous amount of manual labor. The reliance of more patients suffering from glioma would also be a horrible necessity.